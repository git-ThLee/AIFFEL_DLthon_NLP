{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3cc313",
   "metadata": {},
   "source": [
    "## 모듈 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a086d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from soynlp.normalizer import *\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ef0ff",
   "metadata": {},
   "source": [
    "`from soynlp.normalizer import *`  \n",
    "한국어 분석을 위한 pure python code\n",
    "- 학습데이터를 이용하지 않으면서 데이터에 존재하는 단어를 찾거나, 문장을 단어열로 분해, 혹은 품사 판별을 할 수 있는 비지도학습 접근법을 지향합니다.\n",
    "- [Github Link](https://github.com/lovit/soynlp)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e85a7",
   "metadata": {},
   "source": [
    "## 파일 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d2951",
   "metadata": {},
   "source": [
    "### 1) Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b2c14",
   "metadata": {},
   "source": [
    "#### CSV file read (as DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b511b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augment된 데이터를 읽어보자\n",
    "train_data_path =\"/aiffel/aiffel/train_aug_old.csv\"\n",
    "train_data = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbecc8d",
   "metadata": {},
   "source": [
    "#### Data Read (with `tail`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adf57d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19745</th>\n",
       "      <td>희정씨 네 주말에 시간이 넘쳐나나봐 갑자기 왜그러세요 빤짝빤짝 네일했니 네 여름이라...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19746</th>\n",
       "      <td>희정씨 네 주말에 시간이 넘쳐나나봐 갑자기 윗분들 손이 빤짝빤짝 네일했니 네 여름이...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19747</th>\n",
       "      <td>희정씨 네 주말에 시간이 넘쳐나나봐 갑자기 왜그러세요 손이 빤짝빤짝 네일했니 네 여...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19748</th>\n",
       "      <td>희정씨 주말에 네 시간이 넘쳐나나봐 갑자기 왜그러세요 아프시겠다 빤짝빤짝 네일했니 ...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19749</th>\n",
       "      <td>희정씨 네 주말에 시간이 넘쳐나나봐 갑자기 왜그러세요 손이 빤짝빤짝 네일했니 네 여...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            conversation        class\n",
       "19745  희정씨 네 주말에 시간이 넘쳐나나봐 갑자기 왜그러세요 빤짝빤짝 네일했니 네 여름이라...  직장 내 괴롭힘 대화\n",
       "19746  희정씨 네 주말에 시간이 넘쳐나나봐 갑자기 윗분들 손이 빤짝빤짝 네일했니 네 여름이...  직장 내 괴롭힘 대화\n",
       "19747  희정씨 네 주말에 시간이 넘쳐나나봐 갑자기 왜그러세요 손이 빤짝빤짝 네일했니 네 여...  직장 내 괴롭힘 대화\n",
       "19748  희정씨 주말에 네 시간이 넘쳐나나봐 갑자기 왜그러세요 아프시겠다 빤짝빤짝 네일했니 ...  직장 내 괴롭힘 대화\n",
       "19749  희정씨 네 주말에 시간이 넘쳐나나봐 갑자기 왜그러세요 손이 빤짝빤짝 네일했니 네 여...  직장 내 괴롭힘 대화"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4072d87",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79100050",
   "metadata": {},
   "source": [
    "## 데이터 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce731bc4",
   "metadata": {},
   "source": [
    "### 대화 데이터(`conversation`)를 `sentences`에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3edbb915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate sentences..: 100%|██████████| 19750/19750 [00:00<00:00, 1958148.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# 학습할 문장이 담길 배열\n",
    "sentences = []\n",
    "\n",
    "for val in tqdm(train_data['conversation'], desc=\"Generate sentences..\"):\n",
    "    # 전처리가 된 conversation을 val로 받아오기\n",
    "    sentences.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ca4851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19750"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대화 데이터 개수 파악\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e93a87",
   "metadata": {},
   "source": [
    "### 3) 대화 분류값(`class`)를 `labels`에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afab4d1",
   "metadata": {},
   "source": [
    "#### `class` 값은 숫자로 변환하여 `labels`에 저장한다\n",
    "- `협박 관련 대화` &rarr; `0`\n",
    "- `갈취 관련 대화` &rarr; `1`\n",
    "- `직장 관련 대화` &rarr; `2`  \n",
    "- `기타 관련 대화` &rarr; `3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a7890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "class label convert to num...: 100%|██████████| 19750/19750 [00:00<00:00, 1357947.35it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for val in tqdm(train_data['class'], desc=\"class label convert to num...\"):    \n",
    "    if '갈취' in val:\n",
    "        labels.append(1)\n",
    "    if '기타' in val:\n",
    "        labels.append(3)\n",
    "    if '직장' in val:\n",
    "        labels.append(2)\n",
    "    if '협박' in val:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44fe2dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19750"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e8460",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50dc931",
   "metadata": {},
   "source": [
    "## 모델 학습 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ee249",
   "metadata": {},
   "source": [
    "### 1) 모델 학습용 파라미터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94bb73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 최대 길이\n",
    "MAX_LEN = 128\n",
    "# 데이터 묶음 크기\n",
    "BATCH_SIZE = 16\n",
    "# Learning Rate\n",
    "lr = 2e-5\n",
    "# 훈련 횟수\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f8937",
   "metadata": {},
   "source": [
    "### 2) 데이터셋 분할\n",
    "1. `sentences`와 `labels`를 활용\n",
    "2. `8:2` 비율로 `train`, `validation` 데이터셋으로 분할\n",
    "3. 분할 시 `class`별 균등 분할 (`stratify` 옵션 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f2332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 분류와 동일하게 학습데이터 분할\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42, stratify=train_data['class']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ffe1ba",
   "metadata": {},
   "source": [
    "### 3) 사용하지 않는 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2efab533",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109ad89",
   "metadata": {},
   "source": [
    "### 4) 모델 선언\n",
    "1. 모델: `bert-base-multilingual-cased`\n",
    "2. BERT 토크나이저 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c1ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERT 토크나이저와 모델 준비\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27363bee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f1fc7",
   "metadata": {},
   "source": [
    "### 5) 데이터(`train`, `validation`)를 BERT 형식으로 변환\n",
    "1. `예시` &rarr; `[CLS] 안녕하세요 [SEP]`\n",
    "2. 문장 구분 토큰을 추가하여 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb3d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 BERT 입력 형식으로 변환\n",
    "train_encodings = tokenizer(train_sentences, truncation=True, padding=True, max_length=MAX_LEN) # 뒤쪽에 패딩\n",
    "val_encodings = tokenizer(val_sentences, truncation=True, padding=True, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401eb058",
   "metadata": {},
   "source": [
    "### 6) Tensor 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05bc2c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tensor dataset generated!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(100).batch(BATCH_SIZE)\n",
    "\n",
    "print(\"Train tensor dataset generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d35c9084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation tensor dataset generated!\n"
     ]
    }
   ],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).batch(BATCH_SIZE)\n",
    "\n",
    "print(\"Validation tensor dataset generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e61f23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0fb1f6",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f2f87d",
   "metadata": {},
   "source": [
    "### 1) 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43553272",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e524007",
   "metadata": {},
   "source": [
    "### 2) 모델 구조 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71fe7a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e9ec3",
   "metadata": {},
   "source": [
    "### 3) 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a1b9afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "988/988 [==============================] - 505s 495ms/step - loss: 0.5197 - accuracy: 0.8103 - val_loss: 0.2567 - val_accuracy: 0.9165\n",
      "Epoch 2/10\n",
      "988/988 [==============================] - 486s 492ms/step - loss: 0.1846 - accuracy: 0.9379 - val_loss: 0.1356 - val_accuracy: 0.9565\n",
      "Epoch 3/10\n",
      "988/988 [==============================] - 486s 492ms/step - loss: 0.0869 - accuracy: 0.9715 - val_loss: 0.1364 - val_accuracy: 0.9580\n",
      "Epoch 4/10\n",
      "988/988 [==============================] - 486s 492ms/step - loss: 0.0546 - accuracy: 0.9823 - val_loss: 0.0653 - val_accuracy: 0.9818\n",
      "Epoch 5/10\n",
      "988/988 [==============================] - 486s 492ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.0600 - val_accuracy: 0.9848\n",
      "Epoch 6/10\n",
      "988/988 [==============================] - 486s 492ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.0549 - val_accuracy: 0.9843\n",
      "Epoch 7/10\n",
      "988/988 [==============================] - 486s 492ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.0667 - val_accuracy: 0.9785\n",
      "Epoch 8/10\n",
      "988/988 [==============================] - 486s 492ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.0738 - val_accuracy: 0.9790\n",
      "Epoch 9/10\n",
      "988/988 [==============================] - 486s 492ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.0325 - val_accuracy: 0.9901\n",
      "Epoch 10/10\n",
      "988/988 [==============================] - 486s 492ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0559 - val_accuracy: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f4cd074f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0a38f",
   "metadata": {},
   "source": [
    "### 4) 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "030cd62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 36s 144ms/step - loss: 0.0559 - accuracy: 0.9851\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de027c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1dae9",
   "metadata": {},
   "source": [
    "## submission.csv 생성해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc593b67",
   "metadata": {},
   "source": [
    "### 1) 파일 읽기 (`test.json`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f5b1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path =\"/aiffel/aiffel/dktc/data/test.json\"\n",
    "\n",
    "with open(test_data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f6fb8",
   "metadata": {},
   "source": [
    "### 2) 테스트 데이터 읽으면서 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b4466a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicst = list()\n",
    "\n",
    "for key in test:\n",
    "    test_sentence = test[key]['text']\n",
    "    \n",
    "    test_encodings = tokenizer(test_sentence, truncation=True, padding=True, max_length=128, return_tensors=\"tf\")\n",
    "    \n",
    "    test_predictions = model.predict({\n",
    "        \"input_ids\": test_encodings[\"input_ids\"],\n",
    "        \"token_type_ids\": test_encodings[\"token_type_ids\"],\n",
    "        \"attention_mask\": test_encodings[\"attention_mask\"]\n",
    "    }) # [ 0.7805823,  2.6188664, -2.0281641, -0.9672525]\n",
    "    test_class_probabilities = tf.nn.softmax(test_predictions.logits, axis=-1).numpy() # [[0.13297564 0.8358507  0.00801584 0.02315779]]\n",
    "    test_predicted_class = np.argmax(test_class_probabilities, axis=1) # [ 1 ]\n",
    "    test_predicst.append(test_predicted_class[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69504510",
   "metadata": {},
   "source": [
    "### 3) `submission.csv` 파일을 위한 `DataFrame` 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f10044aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_000</th>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_001</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_002</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_004</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_005</th>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_495</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_496</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_497</th>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_498</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_499</th>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class\n",
       "t_000    01\n",
       "t_001    02\n",
       "t_002    02\n",
       "t_004    02\n",
       "t_005    00\n",
       "...     ...\n",
       "t_495    02\n",
       "t_496    02\n",
       "t_497    01\n",
       "t_498    02\n",
       "t_499    00\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def labelnum_to_text(x):\n",
    "    if x == 1 : # 갈취\n",
    "        return '01'\n",
    "    if x == 2 : # 직장\n",
    "        return '02'\n",
    "    if x == 3 : # 기타\n",
    "        return '03'\n",
    "    if x == 0 : # 협박 \n",
    "        return '00'\n",
    "\n",
    "submission = pd.DataFrame({'class':test_predicst}, index=list(test.keys()))\n",
    "submission['class'] = submission['class'].apply(labelnum_to_text)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbef1aa",
   "metadata": {},
   "source": [
    "### 4) CSV 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc60b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일명 설정\n",
    "file_name = \"submission_test5_all_train_data_augment_stratify.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d44e7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 생성\n",
    "submission.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4ad59",
   "metadata": {},
   "source": [
    "# 테스트 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad386a25",
   "metadata": {},
   "source": [
    "1. `OOM Error`로 인해 `MAX_LEN`를 크게 테스트 해보지 못했다. (ex: `300`)\n",
    "    - 약간의 파라미터 수정은 수행하였다.\n",
    "        - `learning rate`, `EPOCH`\n",
    "2. 검증 데이터를 임의로 설정하였다. (`train_aug_old.csv` 파일로부터)\n",
    "3. `from soynlp.normalizer import *`로 전처리된 CSV 파일을 가지고 수행하였다.\n",
    "4. Validation 데이터는 증강하지 않아야 함을 알게되었다.\n",
    "    - 데이터 정보 유출 이슈 등\n",
    "5. 데이터 EDA 관련해서 클래스에 유의미한 정보는 현재 설정한 `128` 값보다 뒤에 있는 경우가 많음을 알게 되었다.\n",
    "    - 편향성 증가 우려가 있음\n",
    "6. `class`를 균일하게 분할하였음에도 (`stratify`) 유의미한 향상은 없는 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
