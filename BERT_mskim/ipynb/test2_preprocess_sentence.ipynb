{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5cff08",
   "metadata": {},
   "source": [
    "## 모듈 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46284ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from soynlp.normalizer import *\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb824f05",
   "metadata": {},
   "source": [
    "`from soynlp.normalizer import *`  \n",
    "한국어 분석을 위한 pure python code\n",
    "- 학습데이터를 이용하지 않으면서 데이터에 존재하는 단어를 찾거나, 문장을 단어열로 분해, 혹은 품사 판별을 할 수 있는 비지도학습 접근법을 지향합니다.\n",
    "- [Github Link](https://github.com/lovit/soynlp)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39c512",
   "metadata": {},
   "source": [
    "## 파일 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bb1ed",
   "metadata": {},
   "source": [
    "### 1) Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7d6c5",
   "metadata": {},
   "source": [
    "#### CSV file read (as DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e231ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path =\"/aiffel/aiffel/dktc/data/train.csv\"\n",
    "train_data = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc8026",
   "metadata": {},
   "source": [
    "#### Data Read (with `tail`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827a2602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>3945</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>준하야 넌 대가리가 왜이렇게 크냐?\\n내 머리가 뭐.\\n밥먹으면 대가리만 크냐 너는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>3946</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>내가 지금 너 아들 김길준 데리고 있어. 살리고 싶으면 계좌에 1억만 보내\\n예.?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>3947</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>나는 씨 같은 사람 보면 참 신기하더라. 어떻게 저렇게 살지.\\n왜 그래. 들리겠어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>3948</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>누구맘대로 여기서 장사하래?\\n이게 무슨일입니까?\\n남의 구역에서 장사하려면 자릿세...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>3949</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>희정씨\\n네?\\n주말에 시간이 넘쳐나나봐\\n갑자기 왜그러세요?\\n손이 빤짝빤짝 네일...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx        class                                       conversation\n",
       "3945  3945    기타 괴롭힘 대화  준하야 넌 대가리가 왜이렇게 크냐?\\n내 머리가 뭐.\\n밥먹으면 대가리만 크냐 너는...\n",
       "3946  3946        갈취 대화  내가 지금 너 아들 김길준 데리고 있어. 살리고 싶으면 계좌에 1억만 보내\\n예.?...\n",
       "3947  3947  직장 내 괴롭힘 대화  나는 씨 같은 사람 보면 참 신기하더라. 어떻게 저렇게 살지.\\n왜 그래. 들리겠어...\n",
       "3948  3948        갈취 대화  누구맘대로 여기서 장사하래?\\n이게 무슨일입니까?\\n남의 구역에서 장사하려면 자릿세...\n",
       "3949  3949  직장 내 괴롭힘 대화  희정씨\\n네?\\n주말에 시간이 넘쳐나나봐\\n갑자기 왜그러세요?\\n손이 빤짝빤짝 네일..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1c613",
   "metadata": {},
   "source": [
    "#### Data Read (by case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0eceab",
   "metadata": {},
   "source": [
    "##### case 1. 협박"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6335498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지금 너 스스로를 죽여달라고 애원하는 것인가?\n",
      " 아닙니다. 죄송합니다.\n",
      " 죽을 거면 혼자 죽지 우리까지 사건에 휘말리게 해? 진짜 죽여버리고 싶게.\n",
      " 정말 잘못했습니다.\n",
      " 너가 선택해. 너가 죽을래 네 가족을 죽여줄까.\n",
      " 죄송합니다. 정말 잘못했습니다.\n",
      " 너에게는 선택권이 없어. 선택 못한다면 너와 네 가족까지 모조리 죽여버릴거야.\n",
      " 선택 못하겠습니다. 한번만 도와주세요.\n",
      " 그냥 다 죽여버려야겠군. 이의 없지?\n",
      " 제발 도와주세요.\n"
     ]
    }
   ],
   "source": [
    "print(train_data['conversation'][0]) # 협박"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f627b1",
   "metadata": {},
   "source": [
    "##### case 2. 기타 괴롭힘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9347b545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\n",
      "그만해. 니들 놀리는거 재미없어.\n",
      "지영아 너가 키 160이지? 그럼 재는 160도 안돼는거네?\n",
      "너 군대도 안가고 좋겠다.\n",
      "니들이 나 작은데 보태준거 있냐?\n",
      "난쟁이들도 장가가고하던데. 너도 희망을 가져봐 \n",
      "더이상 하지마라. \n",
      "그 키크는 수술도 있대잖아? 니네 엄마는 그거 안해주디?\n",
      "나람 해줬어. 저 키로 어찌살아.\n",
      "제발 그만 괴롭히라고!\n"
     ]
    }
   ],
   "source": [
    "print(train_data['conversation'][2]) # 기타 괴롭힘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13085494",
   "metadata": {},
   "source": [
    "##### case 3. 갈취"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c4ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어이 거기\n",
      "예??\n",
      "너 말이야 너. 이리 오라고\n",
      "무슨 일.\n",
      "너 옷 좋아보인다?\n",
      "얘 돈 좀 있나봐\n",
      "아니에요.돈 없어요\n",
      "뒤져서 나오면 넌 죽는다\n",
      "오늘 피시방 콜?\n",
      "콜. 마지막 기회다. 있는거 다 내놔\n",
      "정말 없어요\n"
     ]
    }
   ],
   "source": [
    "print(train_data['conversation'][3]) # 갈취"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e89da",
   "metadata": {},
   "source": [
    "##### case 4. 직장 내 괴롭힘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db09fffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 씨 같은 사람 보면 참 신기하더라. 어떻게 저렇게 살지.\n",
      "왜 그래. 들리겠어.\n",
      "들리라고 해. 아니 일 못해 눈치 없어. 본인도 슬슬 깨달아야 되지 않나?\n",
      "하긴 그래서 저번에 부장님도.\n",
      "그렇다니깐! 부장님이 진짜 착하신 분인데 오죽 답답했으면 말을 했겠어?\n",
      "그러게.\n",
      "회사생활 같이 한게 몇년인데 대답 하나 제대로 네 하고 싹싹하게 하는걸 못봤어.\n",
      "나도 그건 못본거 같다.\n",
      "지금도 그래. 야 야! 너 바로 앞에서 얘기하는데 귀가 먹어서 안들리는거니 안들리는척 하는거니? 뭐 말 좀 해봐?\n",
      "야 너 왜 그래.\n",
      "말씀이 너무 심하신거 아니에요?\n"
     ]
    }
   ],
   "source": [
    "print(train_data['conversation'][3947]) # 직장 내 괴롭힘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3d788",
   "metadata": {},
   "source": [
    "#### Data Read (Check null data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56fa3612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx             0\n",
       "class           0\n",
       "conversation    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210c23e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e92072",
   "metadata": {},
   "source": [
    "## 데이터 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9bbd97",
   "metadata": {},
   "source": [
    "### 1) 문장 전처리 함수 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9155db",
   "metadata": {},
   "source": [
    "#### `preprocess_sentence()`\n",
    "1. 영어, 한국어가 아닌 경우 공백 (` `) 처리\n",
    "2. 두 개 이상의 느낌표(`!+`)가 있을 경우 느낌표 하나로 처리\n",
    "3. 두 개 이상의 물음표(`\\?+`)가 있을 경우 물음표 하나로 처리\n",
    "4. `?`, `.`, `!`, `,` 가 있을 경우 그 주위에 공백을 추가\n",
    "5. 연속적인 공백이 있을 시 공백을 하나로 처리\n",
    "6. 문장 앞뒤의 공백과 개행문자를 제거(`strip`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82bf018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    emoticon_normalize(sentence)\n",
    "    repeat_normalize(sentence)\n",
    "    sentence = re.sub(r'([^a-zA-Zㄱ-ㅎ가-힣?.!,])', \" \", sentence)\n",
    "    sentence = re.sub(r'!+', '!', sentence)\n",
    "    sentence = re.sub(r'\\?+', '?', sentence)\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a70a2",
   "metadata": {},
   "source": [
    "### 2) `preprocess_sentence()` 사용해 학습할 문장(`sentences`) 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5850d756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate sentences..: 100%|██████████| 3950/3950 [00:01<00:00, 3328.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# 학습할 문장이 담길 배열\n",
    "sentences = []\n",
    "\n",
    "for val in tqdm(train_data['conversation'], desc=\"Generate sentences..\"):\n",
    "    # preprocess_sentence()로 문장(val)을 전처리하여 배열에 저장\n",
    "    sentences.append(preprocess_sentence(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1040af5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3950"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대화 데이터 개수 파악\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dc182f",
   "metadata": {},
   "source": [
    "### 3) 대화 분류값(`class`)를 `labels`에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda7cfd",
   "metadata": {},
   "source": [
    "#### `class` 값은 숫자로 변환하여 `labels`에 저장한다\n",
    "- `협박 관련 대화` &rarr; `0`\n",
    "- `갈취 관련 대화` &rarr; `1`\n",
    "- `직장 관련 대화` &rarr; `2`  \n",
    "- `기타 관련 대화` &rarr; `3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "263817c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "class label convert to num...: 100%|██████████| 3950/3950 [00:00<00:00, 1314463.73it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for val in tqdm(train_data['class'], desc=\"class label convert to num...\"):    \n",
    "    if '갈취' in val:\n",
    "        labels.append(1)\n",
    "    if '기타' in val:\n",
    "        labels.append(3)\n",
    "    if '직장' in val:\n",
    "        labels.append(2)\n",
    "    if '협박' in val:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eaa1c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3950"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels 개수 파악\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ddf9f",
   "metadata": {},
   "source": [
    "### 4) 사용하지 않는 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b42c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1609a8e8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08731db6",
   "metadata": {},
   "source": [
    "## 모델 학습 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51db11f",
   "metadata": {},
   "source": [
    "### 1) 모델 학습용 파라미터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b24b4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 최대 길이\n",
    "MAX_LEN = 128\n",
    "# 데이터 묶음 크기\n",
    "BATCH_SIZE = 16\n",
    "# Learning Rate\n",
    "lr = 1e-5\n",
    "# 훈련 횟수\n",
    "EPOCH = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601585cc",
   "metadata": {},
   "source": [
    "### 2) 데이터셋 분할\n",
    "1. `sentences`와 `labels`를 활용\n",
    "2. `8:2` 비율로 `train`, `validation` 데이터셋으로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abdf0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분할\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82b126",
   "metadata": {},
   "source": [
    "### 3) 모델 선언\n",
    "1. 모델: `bert-base-multilingual-cased`\n",
    "2. BERT 토크나이저 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5585c899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERT 토크나이저와 모델 준비\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe5509",
   "metadata": {},
   "source": [
    "### 4) 데이터(`train`, `validation`)를 BERT 형식으로 변환\n",
    "1. `예시` &rarr; `[CLS] 안녕하세요 [SEP]`\n",
    "2. 문장 구분 토큰을 추가하여 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b37c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 BERT 입력 형식으로 변환\n",
    "train_encodings = tokenizer(train_sentences, truncation=True, padding=True, max_length=MAX_LEN) # 뒤쪽에 패딩\n",
    "val_encodings = tokenizer(val_sentences, truncation=True, padding=True, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d08e0",
   "metadata": {},
   "source": [
    "### 5) Tensor 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b38d7ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tensor dataset generated!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(100).batch(BATCH_SIZE)\n",
    "\n",
    "print(\"Train tensor dataset generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "192d89d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation tensor dataset generated!\n"
     ]
    }
   ],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).batch(BATCH_SIZE)\n",
    "\n",
    "print(\"Validation tensor dataset generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df0a130",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f2b70",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef1fcb",
   "metadata": {},
   "source": [
    "### 1) 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fb57b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92029a33",
   "metadata": {},
   "source": [
    "### 2) 모델 구조 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "689d9b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a71cd22",
   "metadata": {},
   "source": [
    "### 3) 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e44eb056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "198/198 [==============================] - 113s 494ms/step - loss: 1.1329 - accuracy: 0.5047 - val_loss: 0.6991 - val_accuracy: 0.7316\n",
      "Epoch 2/3\n",
      "198/198 [==============================] - 97s 493ms/step - loss: 0.6143 - accuracy: 0.7908 - val_loss: 0.5554 - val_accuracy: 0.8089\n",
      "Epoch 3/3\n",
      "198/198 [==============================] - 97s 492ms/step - loss: 0.4317 - accuracy: 0.8453 - val_loss: 0.5386 - val_accuracy: 0.8266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f215c2c77c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3da74",
   "metadata": {},
   "source": [
    "### 4) 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7472d518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 7s 143ms/step - loss: 0.5386 - accuracy: 0.8266\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8f99a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bebcd2",
   "metadata": {},
   "source": [
    "## submission.csv 생성해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d65dbb",
   "metadata": {},
   "source": [
    "### 1) 파일 읽기 (`test.json`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aab5dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path =\"/aiffel/aiffel/dktc/data/test.json\"\n",
    "\n",
    "with open(test_data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e7ec36",
   "metadata": {},
   "source": [
    "### 2) 테스트 데이터 읽으면서 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97a40d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicst = list()\n",
    "\n",
    "for key in test:\n",
    "    test_sentence = test[key]['text']\n",
    "    \n",
    "    test_encodings = tokenizer(test_sentence, truncation=True, padding=True, max_length=128, return_tensors=\"tf\")\n",
    "    \n",
    "    test_predictions = model.predict({\n",
    "        \"input_ids\": test_encodings[\"input_ids\"],\n",
    "        \"token_type_ids\": test_encodings[\"token_type_ids\"],\n",
    "        \"attention_mask\": test_encodings[\"attention_mask\"]\n",
    "    }) # [ 0.7805823,  2.6188664, -2.0281641, -0.9672525]\n",
    "    test_class_probabilities = tf.nn.softmax(test_predictions.logits, axis=-1).numpy() # [[0.13297564 0.8358507  0.00801584 0.02315779]]\n",
    "    test_predicted_class = np.argmax(test_class_probabilities, axis=1) # [ 1 ]\n",
    "    test_predicst.append(test_predicted_class[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00451098",
   "metadata": {},
   "source": [
    "### 3) `submission.csv` 파일을 위한 `DataFrame` 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "205bf703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_000</th>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_001</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_002</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_004</th>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_005</th>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_495</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_496</th>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_497</th>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_498</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_499</th>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class\n",
       "t_000    00\n",
       "t_001    02\n",
       "t_002    02\n",
       "t_004    03\n",
       "t_005    00\n",
       "...     ...\n",
       "t_495    02\n",
       "t_496    03\n",
       "t_497    01\n",
       "t_498    02\n",
       "t_499    00\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def labelnum_to_text(x):\n",
    "    if x == 1 : # 갈취\n",
    "        return '01'\n",
    "    if x == 2 : # 직장\n",
    "        return '02'\n",
    "    if x == 3 : # 기타\n",
    "        return '03'\n",
    "    if x == 0 : # 협박 \n",
    "        return '00'\n",
    "\n",
    "submission = pd.DataFrame({'class':test_predicst}, index=list(test.keys()))\n",
    "submission['class'] = submission['class'].apply(labelnum_to_text)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c7959",
   "metadata": {},
   "source": [
    "### 4) CSV 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c2c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일명 설정\n",
    "file_name = \"submission_test2_preprocess_sentence.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e87329df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 생성\n",
    "submission.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ea916",
   "metadata": {},
   "source": [
    "# 테스트 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7556ef",
   "metadata": {},
   "source": [
    "1. `OOM Error`로 인해 `MAX_LEN`를 크게 테스트 해보지 못했다. (ex: `300`)\n",
    "2. 검증 데이터를 임의로 설정하였다. (`train.csv` 파일로부터)\n",
    "3. 데이터에 대해 전처리를 `preprocess_sentence()`를 통해 수행하였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
