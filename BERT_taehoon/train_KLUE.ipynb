{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d92a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7efa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from soynlp.normalizer import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "    \n",
    "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
    "    \n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "        # input_id는 워드 임베딩을 위한 문장의 정수 인코딩\n",
    "        input_id = tokenizer.encode(example, \n",
    "                                    max_length=max_seq_len, \n",
    "                                    pad_to_max_length=True,\n",
    "                                   )\n",
    "        \n",
    "        # attention_mask는 실제 단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스\n",
    "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
    "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
    "        \n",
    "        # token_type_id은 세그먼트 인코딩\n",
    "        token_type_id = [0] * max_seq_len\n",
    "        \n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(label)\n",
    "    \n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "    \n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "    \n",
    "    return (input_ids, attention_masks, token_type_ids), data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db816d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertForMultiClassClassification(tf.keras.Model):\n",
    "    def __init__(self, model_name, num_classes, dropout_rate=0.3):\n",
    "        super(TFBertForMultiClassClassification, self).__init__()\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
    "                                                activation='softmax', \n",
    "                                                name='classifier')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        input_ids, attention_mask, token_type_ids = inputs\n",
    "        outputs = self.bert(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        cls_token = outputs[1]\n",
    "        if training:\n",
    "            cls_token = self.dropout(cls_token, training=training)\n",
    "        prediction = self.classifier(cls_token)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFRobertaModel, RobertaTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class TFRobertaForMultiClassClassification(tf.keras.Model):\n",
    "    def __init__(self, model_name, num_classes, dropout_rate=0.3):\n",
    "        super(TFRobertaForMultiClassClassification, self).__init__()\n",
    "        self.roberta = AutoTokenizer.from_pretrained(model_name, from_pt=True)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
    "                                                activation='softmax', \n",
    "                                                name='classifier')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        input_ids, attention_mask = inputs  # RoBERTa는 token_type_ids가 필요하지 않습니다.\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_token = outputs[1]\n",
    "        if training:\n",
    "            cls_token = self.dropout(cls_token, training=training)\n",
    "        prediction = self.classifier(cls_token)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    emoticon_normalize(sentence)  # 이모티콘을 정규화합니다.\n",
    "    repeat_normalize(sentence)    # 반복되는 문자를 정규화합니다.\n",
    "    sentence = re.sub(r'([^a-zA-Zㄱ-ㅎ가-힣])', \" \", sentence)  # 영문, 한글 및 자음/모음을 제외한 문자를 공백으로 치환합니다.\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)  # 연속된 공백을 하나의 공백으로 치환합니다.\n",
    "    sentence = sentence.strip()  # 문장의 양 끝에 있는 공백을 제거합니다.\n",
    "    return sentence  # 전처리된 문장을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    # 중복 제거 \n",
    "    df = df.drop_duplicates(subset=['conversation']) \n",
    "    \n",
    "    # 문장 정규화\n",
    "    df['conversation'] = df['conversation'].apply(preprocess_sentence)\n",
    "    \n",
    "    # 결측치 제거\n",
    "    df = df.dropna(subset=['conversation'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc5b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_text_to_num(df):\n",
    "    # 레이블 값을 숫자로 매핑\n",
    "    label_mapping = {\n",
    "        '협박 대화': 0,\n",
    "        '갈취 대화': 1,\n",
    "        '직장 내 괴롭힘 대화': 2,\n",
    "        '기타 괴롭힘 대화': 3\n",
    "    }\n",
    "\n",
    "    df['class'] = df['class'].map(label_mapping)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug(x,y,classs):\n",
    "    def random_deletion(words, p=0.1):\n",
    "        if len(words) == 1:\n",
    "            return words\n",
    "\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            r = random.uniform(0, 1)\n",
    "            if r > p:\n",
    "                new_words.append(word)\n",
    "\n",
    "        if len(new_words) == 0:\n",
    "            rand_int = random.randint(0, len(words)-1)\n",
    "            return [words[rand_int]]\n",
    "\n",
    "        return ''.join(new_words)\n",
    "\n",
    "    def swap_word(new_words):\n",
    "        n = 5\n",
    "        for _ in range(n):\n",
    "            random_idx_1 = random.randint(0, len(new_words)-1)\n",
    "            random_idx_2 = random_idx_1\n",
    "            counter = 0\n",
    "\n",
    "            while random_idx_2 == random_idx_1:\n",
    "                random_idx_2 = random.randint(0, len(new_words)-1)\n",
    "                counter += 1\n",
    "                if counter > 3:\n",
    "                    return new_words\n",
    "\n",
    "            new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "        return ' '.join(new_words)\n",
    "\n",
    "    def random_swap(words):\n",
    "        new_words = list()\n",
    "        for word in words:\n",
    "            new_words.append(swap_word(word.split()))\n",
    "\n",
    "        return new_words\n",
    "    df = pd.concat([x,y],axis=1).reset_index(drop=True)\n",
    "    df_rd = df[df['class']==classs].copy()\n",
    "    df_rd['conversation'] = df_rd['conversation'].apply(random_deletion)\n",
    "    df_rs = df[df['class']==classs].copy()\n",
    "    df_rs['conversation'] = random_swap(df_rs['conversation'].values)\n",
    "    \n",
    "    df_concated = pd.concat([df, df_rs])\n",
    "    return df_concated.loc[:,['conversation']] , df_concated['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157a108",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73584540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# data load \n",
    "train = pd.read_csv(train_path,index_col=0)\n",
    "\n",
    "# preprocessing\n",
    "train = preprocessing(train)\n",
    "\n",
    "\n",
    "# 라벨 숫자 변환\n",
    "train = class_text_to_num(train)\n",
    "\n",
    "# 기타 에서 돈 단어 제거\n",
    "train['conversation'] = train[['class','conversation']].apply(lambda x : x[1].replace('돈','') if x[0] == 3 else x[1], axis=1)\n",
    "# 협박 에서 돈 단어 제거 \n",
    "train['conversation'] = train[['class','conversation']].apply(lambda x : x[1].replace('돈','') if x[0] == 0 else x[1], axis=1)\n",
    "\n",
    "\n",
    "# 모델 load \n",
    "if model_name == 'klue/bert-base':\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = TFBertForMultiClassClassification(model_name, class_num)\n",
    "elif model_name == 'klue/roberta-small':\n",
    "    tokenizer = AutoModel.from_pretrained(model_name)    \n",
    "    model = TFBertForMultiClassClassification(model_name, class_num)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(\n",
    "    train.drop('class',axis=1), train['class'], test_size=0.2, random_state=42 , stratify=train['class']\n",
    ")\n",
    "# Aug\n",
    "train_x, train_y = aug(train_x, train_y, 0)\n",
    "train_x, train_y = aug(train_x, train_y, 1)\n",
    "train_x, train_y = aug(train_x, train_y, 3)\n",
    "\n",
    "# 토크나이저\n",
    "train_X, train_Y = convert_examples_to_features(\n",
    "    train_x['conversation'], train_y, \n",
    "    max_seq_len=max_len, tokenizer=tokenizer\n",
    ")\n",
    "val_X, val_Y = convert_examples_to_features(\n",
    "    val_x['conversation'], val_y, \n",
    "    max_seq_len=max_len, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 옵티마이저, loss\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate= lr)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# model compile\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Define the learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "    if epoch == 0:\n",
    "        return lr\n",
    "    elif epoch == 1 :\n",
    "        return 0.00005 # 5e-5 , 0.00005\n",
    "    elif epoch == 2 :\n",
    "        return 0.000001\n",
    "    elif epoch == 3 :\n",
    "        return 0.000005\n",
    "    elif epoch == 4 :\n",
    "        return 0.0000001\n",
    "    elif epoch == 5 :\n",
    "        return 0.0000005\n",
    "    elif epoch == 6 :\n",
    "        return 0.00000001\n",
    "    else:\n",
    "        return 0.00000001\n",
    "\n",
    "# Create the LearningRateScheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_X, train_Y, \n",
    "    validation_data=(val_X,val_Y),\n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size, \n",
    "    callbacks=[lr_scheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216bd543",
   "metadata": {},
   "source": [
    "- 수정사항 :\n",
    "    1. stratify=train['class'] 으로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f253ec54",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train.csv'\n",
    "val_path = './val.csv'\n",
    "model_name = 'klue/bert-base' # klue/roberta-large klue/bert-base\n",
    "class_num = 4 \n",
    "max_len = 200\n",
    "lr = 5e-5\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# 메모리 해제\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3db50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef9bea33",
   "metadata": {},
   "source": [
    "# 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54730c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 기타 제외 가해자만 남기기 \n",
    "# 직장 제외 데이터 증강(랜덤 스위치), 데이터 삭제\n",
    "# 기타 에서 '돈' 키워드 제거 - 상승\n",
    "# 0번(협박)만 증강 2번\n",
    "# 제출 : 0.8275\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 실제 예측값 생성\n",
    "real_predictions = model.predict(val_X)\n",
    "\n",
    "# 예측값을 레이블로 변환\n",
    "real_predicted_labels = np.argmax(real_predictions, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "real_accuracy = accuracy_score(val_Y, real_predicted_labels)\n",
    "print(f\"Real Accuracy: {real_accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 생성\n",
    "real_report = classification_report(val_Y, real_predicted_labels, target_names=[f\"Class {i}\" for i in range(4)])\n",
    "print(real_report)\n",
    "\n",
    "# F1 스코어 계산\n",
    "real_f1 = f1_score(val_Y, real_predicted_labels, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score (based on real predictions): {real_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d34d055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81add4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 기타 제외 가해자만 남기기 \n",
    "# 직장 제외 데이터 증강(랜덤 스위치), 데이터 삭제\n",
    "# 기타 에서 '돈' 키워드 제거 - 상승\n",
    "# 제출 : 0.8575\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 실제 예측값 생성\n",
    "real_predictions = model.predict(val_X)\n",
    "\n",
    "# 예측값을 레이블로 변환\n",
    "real_predicted_labels = np.argmax(real_predictions, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "real_accuracy = accuracy_score(val_Y, real_predicted_labels)\n",
    "print(f\"Real Accuracy: {real_accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 생성\n",
    "real_report = classification_report(val_Y, real_predicted_labels, target_names=[f\"Class {i}\" for i in range(4)])\n",
    "print(real_report)\n",
    "\n",
    "# F1 스코어 계산\n",
    "real_f1 = f1_score(val_Y, real_predicted_labels, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score (based on real predictions): {real_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a58b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 기타 제외 가해자만 남기기 \n",
    "# 직장 제외 데이터 증강(랜덤 스위치), 데이터 삭제\n",
    "# 제출 : 0.845\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 실제 예측값 생성\n",
    "real_predictions = model.predict(val_X)\n",
    "\n",
    "# 예측값을 레이블로 변환\n",
    "real_predicted_labels = np.argmax(real_predictions, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "real_accuracy = accuracy_score(val_Y, real_predicted_labels)\n",
    "print(f\"Real Accuracy: {real_accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 생성\n",
    "real_report = classification_report(val_Y, real_predicted_labels, target_names=[f\"Class {i}\" for i in range(4)])\n",
    "print(real_report)\n",
    "\n",
    "# F1 스코어 계산\n",
    "real_f1 = f1_score(val_Y, real_predicted_labels, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score (based on real predictions): {real_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d9a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 기타 제외 가해자만 남기기 \n",
    "# 직장 제외 데이터 증강(랜덤 스위치)\n",
    "# 제출 : 0.76\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 실제 예측값 생성\n",
    "real_predictions = model.predict(val_X)\n",
    "\n",
    "# 예측값을 레이블로 변환\n",
    "real_predicted_labels = np.argmax(real_predictions, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "real_accuracy = accuracy_score(val_Y, real_predicted_labels)\n",
    "print(f\"Real Accuracy: {real_accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 생성\n",
    "real_report = classification_report(val_Y, real_predicted_labels, target_names=[f\"Class {i}\" for i in range(4)])\n",
    "print(real_report)\n",
    "\n",
    "# F1 스코어 계산\n",
    "real_f1 = f1_score(val_Y, real_predicted_labels, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score (based on real predictions): {real_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4cd719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632dafc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 기타 제외 가해자만 남기기\n",
    "# 제출 : 0.805\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 실제 예측값 생성\n",
    "real_predictions = model.predict(val_X)\n",
    "\n",
    "# 예측값을 레이블로 변환\n",
    "real_predicted_labels = np.argmax(real_predictions, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "real_accuracy = accuracy_score(val_Y, real_predicted_labels)\n",
    "print(f\"Real Accuracy: {real_accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 생성\n",
    "real_report = classification_report(val_Y, real_predicted_labels, target_names=[f\"Class {i}\" for i in range(4)])\n",
    "print(real_report)\n",
    "\n",
    "# F1 스코어 계산\n",
    "real_f1 = f1_score(val_Y, real_predicted_labels, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score (based on real predictions): {real_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb63b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Real Accuracy: 0.8987\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     협박 0       0.89      0.88      0.88       179\n",
    "     갈취 1       0.88      0.89      0.89       195\n",
    "     직장 2       1.00      0.87      0.93       194\n",
    "     기타 3       0.85      0.96      0.90       202\n",
    "\n",
    "    accuracy                           0.90       770\n",
    "   macro avg       0.90      0.90      0.90       770\n",
    "weighted avg       0.90      0.90      0.90       770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a8fe55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b98a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전체 가해자만 남기기\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 실제 예측값 생성\n",
    "real_predictions = model.predict(val_X)\n",
    "\n",
    "# 예측값을 레이블로 변환\n",
    "real_predicted_labels = np.argmax(real_predictions, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "real_accuracy = accuracy_score(val_Y, real_predicted_labels)\n",
    "print(f\"Real Accuracy: {real_accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 생성\n",
    "real_report = classification_report(val_Y, real_predicted_labels, target_names=[f\"Class {i}\" for i in range(4)])\n",
    "print(real_report)\n",
    "\n",
    "# F1 스코어 계산\n",
    "real_f1 = f1_score(val_Y, real_predicted_labels, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score (based on real predictions): {real_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e6963b",
   "metadata": {},
   "source": [
    "Real Accuracy: 0.8651\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     협박(0)       0.92      0.82      0.87       178\n",
    "     갈취(1)       0.77      0.93      0.84       195\n",
    "     직장(2)       0.91      0.95      0.93       194\n",
    "     기타(3)       0.89      0.76      0.82       204\n",
    "\n",
    "    accuracy                           0.87       771\n",
    "   macro avg       0.87      0.87      0.87       771\n",
    "weighted avg       0.87      0.87      0.86       771\n",
    "\n",
    "\n",
    "- 협박(Class: 협박)\n",
    "\n",
    "\n",
    "상황: 협박 클래스의 경우 정밀도와 재현율이 비교적 높은 편입니다. 그러나 재현율이 약간 낮은 편이며, 이는 실제 협박 케이스 중에서 일부를 놓치고 있다는 의미입니다.\n",
    "해결 방법: 재현율을 높이기 위해 실제 협박 사례가 누락되지 않도록 `데이터를 추가`하는 것이 좋을 수 있습니다. 협박 클래스에 대한 추가 데이터를 확보하거나 수집하여 모델이 협박을 더 잘 인식하고 예측하도록 돕는 것이 가능합니다.\n",
    "\n",
    "- 갈취(Class: 갈취)\n",
    "\n",
    "상황: 갈취 클래스의 경우 재현율이 높은 편으로, 대부분의 갈취 사례를 모델이 예측하는 것으로 보입니다. 그러나 정밀도가 상대적으로 낮아, 모델이 갈취로 잘못 예측하는 경우가 있을 수 있습니다.\n",
    "해결 방법: 정밀도를 향상시키기 위해 모델이 갈취로 잘못 예측하는 경우를 줄일 필요가 있습니다. 이를 위해 추가 데이터 수집 대신 모델의 하이퍼파라미터를 조정하거나 `데이터 전처리`를 통해 모델이 갈취 클래스를 더 잘 구분하도록 돕는 것이 중요할 수 있습니다.\n",
    "\n",
    "- 직장(Class: 직장)\n",
    "\n",
    "상황: 직장 클래스의 경우 정밀도와 재현율이 높은 편으로, 모델이 직장 사례를 예측하는 데 잘 성공하고 있습니다.\n",
    "해결 방법: 현재 상태에서는 특별히 추가적인 데이터나 조치가 필요하지 않아 보입니다. 모델이 직장 클래스를 잘 예측하고 있으므로 유사한 성능을 유지하는 것이 중요합니다.\n",
    "\n",
    "- 기타(Class: 기타)\n",
    "\n",
    "상황: 기타 클래스의 경우 정밀도와 재현율이 상대적으로 높은 편입니다. 그러나 재현율이 낮은 편으로, 실제 기타 사례 중에서 일부를 놓치고 있다는 의미입니다.\n",
    "해결 방법: 재현율을 높이기 위해 기타 클래스의 실제 케이스가 누락되지 않도록 데이터를 추가하는 것이 도움이 될 수 있습니다. `기타 클래스에 대한 더 많은 다양한 예시를 모델이 학습하게 함으로써 모델의 일반화 능력을 향상`시킬 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac8fa25",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ee957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features_test(examples, max_seq_len, tokenizer):\n",
    "    \n",
    "    input_ids, attention_masks, token_type_ids = [], [], []\n",
    "    \n",
    "    for example in tqdm(examples, total=len(examples)):\n",
    "        # input_id는 워드 임베딩을 위한 문장의 정수 인코딩\n",
    "        input_id = tokenizer.encode(example, max_length=max_seq_len, \n",
    "                                    pad_to_max_length=True)\n",
    "        \n",
    "        # attention_mask는 실제 단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스\n",
    "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
    "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
    "        \n",
    "        # token_type_id은 세그먼트 인코딩\n",
    "        token_type_id = [0] * max_seq_len\n",
    "        \n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "    \n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "    \n",
    "    return (input_ids, attention_masks, token_type_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipeline(model, tokenizer, max_len):\n",
    "    \n",
    "    test_data_path = \"./data/test.json\"\n",
    "    with open(test_data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        test_data = json.load(json_file)\n",
    "        \n",
    "    test = pd.DataFrame({'file_name':list(test_data.keys()), 'conversation': list(test_data.values())})\n",
    "    test['conversation'] = test['conversation'].apply(lambda x : x['text'])\n",
    "    \n",
    "    # preprocessing\n",
    "    test['conversation'] = test['conversation'].apply(preprocess_sentence)\n",
    "    \n",
    "    # 토크나이저\n",
    "    test_X = convert_examples_to_features_test(\n",
    "        test['conversation'],\n",
    "        max_seq_len=max_len, \n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    \n",
    "    # 예측\n",
    "    predictions = model.predict(test_X)\n",
    "    test_class_probabilities = tf.nn.softmax(predictions, axis=-1).numpy() # [[0.13297564 0.8358507  0.00801584 0.02315779]]\n",
    "    test_predicted_class = np.argmax(test_class_probabilities, axis=1) # [ 1 ]\n",
    "    \n",
    "    return test_predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8bedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_pipeline(model, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19629c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/submission.csv')\n",
    "submission['class'] = predictions\n",
    "submission.to_csv('submissions/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ae22f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
