{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5724d3",
   "metadata": {},
   "source": [
    "## 모듈 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from soynlp.normalizer import *\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f221bb",
   "metadata": {},
   "source": [
    "`from soynlp.normalizer import *`  \n",
    "한국어 분석을 위한 pure python code\n",
    "- 학습데이터를 이용하지 않으면서 데이터에 존재하는 단어를 찾거나, 문장을 단어열로 분해, 혹은 품사 판별을 할 수 있는 비지도학습 접근법을 지향합니다.\n",
    "- [Github Link](https://github.com/lovit/soynlp)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1def8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# 메모리 해제\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9207f",
   "metadata": {},
   "source": [
    "## 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path =\"./train_ai_last.csv\"\n",
    "train_data = pd.read_csv(train_data_path,index_col=0)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b87aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_path =\"/aiffel/aiffel/dktc/data/train.csv\"\n",
    "# train_data = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c8e60",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cee11a",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4cc2b5",
   "metadata": {},
   "source": [
    "## 문장 전처리 함수 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed63f7",
   "metadata": {},
   "source": [
    "### 1) `preprocess_sentence()`\n",
    "1. 영어, 한국어가 아닌 경우 공백 (` `) 처리\n",
    "2. 두 개 이상의 느낌표(`!+`)가 있을 경우 느낌표 하나로 처리\n",
    "3. 두 개 이상의 물음표(`\\?+`)가 있을 경우 물음표 하나로 처리\n",
    "4. `?`, `.`, `!`, `,` 가 있을 경우 그 주위에 공백을 추가\n",
    "5. 연속적인 공백이 있을 시 공백을 하나로 처리\n",
    "6. 문장 앞뒤의 공백과 개행문자를 제거(`strip`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    emoticon_normalize(sentence)\n",
    "    repeat_normalize(sentence)\n",
    "    sentence = re.sub(r'([^a-zA-Zㄱ-ㅎ가-힣?.!,])', \" \", sentence)\n",
    "    sentence = re.sub(r'!+', '!', sentence)\n",
    "    sentence = re.sub(r'\\?+', '?', sentence)\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb419c64",
   "metadata": {},
   "source": [
    "### 2) `preprocess_sentence2()`\n",
    "1. 영어, 한국어가 아닌 경우 공백 (` `) 처리\n",
    "2. 연속적인 공백이 있을 시 공백을 하나로 처리\n",
    "3. 문장 앞뒤의 공백과 개행문자를 제거(`strip`)\n",
    "4. 위 함수를 거친 문장은 문법기호(`?`, `!`, `,` 등)도 모두 제거됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd322ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence2(sentence):\n",
    "    emoticon_normalize(sentence)\n",
    "    repeat_normalize(sentence)\n",
    "    sentence = re.sub(r'([^a-zA-Zㄱ-ㅎ가-힣])', \" \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef40a84a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175a282",
   "metadata": {},
   "source": [
    "## 문장 전처리 함수를 사용하여 학습할 문장(`sentences`) 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습할 문장이 담길 배열\n",
    "sentences = []\n",
    "\n",
    "for val in tqdm(train_data['conversation'], desc=\"Generate sentences..\"):\n",
    "    # preprocess_sentence2()로 문장(val)을 전처리하여 배열에 저장\n",
    "    sentences.append(preprocess_sentence2(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13720c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### preprocess_sentence() 케이스 사용 시 해당 함수 내용을 써보자\n",
    "#### 테스트는 preprocess_sentence()를 거친 데이터 기준으로 수행됨\n",
    "def dummy():\n",
    "    # 학습할 문장이 담길 배열\n",
    "    sentences2 = []\n",
    "\n",
    "    for val in tqdm(train_data['conversation'], desc=\"Generate sentences..\"):\n",
    "        # preprocess_sentence()로 문장(val)을 전처리하여 배열에 저장\n",
    "        sentences.append(preprocess_sentence(val))\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b67d7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d000f6e",
   "metadata": {},
   "source": [
    "## 대화 종류(`class`) 문장을 숫자로 변환\n",
    "\n",
    "---\n",
    "\n",
    "`협박 관련 대화` &rarr; `0`  \n",
    "`갈취 관련 대화` &rarr; `1`  \n",
    "`직장 관련 대화` &rarr; `2`  \n",
    "`기타 관련 대화` &rarr; `3`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for val in tqdm(train_data['class'], desc=\"class label convert to num...\"):    \n",
    "    if '갈취' in val:\n",
    "        labels.append(1)\n",
    "    if '기타' in val:\n",
    "        labels.append(3)\n",
    "    if '직장' in val:\n",
    "        labels.append(2)\n",
    "    if '협박' in val:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0c190",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764dcef9",
   "metadata": {},
   "source": [
    "## 데이터셋(`sentences`, `labels`)을 8:2 (`train`:`test`)로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분할\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_deletion(words, p=0.3):\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > p:\n",
    "            new_words.append(word)\n",
    "\n",
    "    if len(new_words) == 0:\n",
    "        rand_int = random.randint(0, len(words)-1)\n",
    "        return [words[rand_int]]\n",
    "\n",
    "    return ''.join(new_words)\n",
    "\n",
    "def swap_word(new_words):\n",
    "    random_idx_1 = random.randint(0, len(new_words)-1)\n",
    "    random_idx_2 = random_idx_1\n",
    "    counter = 0\n",
    "\n",
    "    while random_idx_2 == random_idx_1:\n",
    "        random_idx_2 = random.randint(0, len(new_words)-1)\n",
    "        counter += 1\n",
    "        if counter > 3:\n",
    "            return new_words\n",
    "\n",
    "    new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "    return new_words\n",
    "\n",
    "def random_swap(words, n=3):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        new_words = swap_word(new_words)\n",
    "\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('증강 전 : ', len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splted = pd.DataFrame({\n",
    "    'sentence': train_sentences,\n",
    "    'class':train_labels\n",
    "})\n",
    "train_splted_rd = train_splted.copy()\n",
    "train_splted_rd['sentence'] = train_splted_rd['sentence'].apply(random_deletion)\n",
    "\n",
    "\n",
    "\n",
    "train_splted_rs = train_splted.copy()\n",
    "train_splted_rs['sentence'] = random_swap(train_splted_rs['sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_concated = pd.concat([train_splted,train_splted_rd,train_splted_rs])\n",
    "train_concated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75720eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sentences = list(train_concated['sentence'].values)\n",
    "# train_labels = list(train_concated['class'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee0ee5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870825f0",
   "metadata": {},
   "source": [
    "## BERT 토크나이저 & 모델 준비\n",
    "학습된 `BERT` 모델 사용 &rarr; `bert-base-multilingual-cased`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 토크나이저와 모델 준비\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69626b05",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f817979",
   "metadata": {},
   "source": [
    "## 모델 파라미터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bac0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 최대 길이\n",
    "MAX_LEN = 200\n",
    "# 데이터 묶음 크기\n",
    "BATCH_SIZE = 16\n",
    "# Learning Rate\n",
    "lr = 5e-5 # 5e-5 , 1e-4 \n",
    "# 훈련 횟수\n",
    "EPOCH = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35edc0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f3dcb",
   "metadata": {},
   "source": [
    "## 일반 문장을 BERT 입력 형식으로 변환\n",
    "`예시` &rarr; `[CLS] 안녕하세요 [SEP]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0519599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 BERT 입력 형식으로 변환\n",
    "train_encodings = tokenizer(train_sentences, truncation=True, padding=True, max_length=MAX_LEN) # 뒤쪽에 패딩\n",
    "val_encodings = tokenizer(val_sentences, truncation=True, padding=True, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f1a01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb3145",
   "metadata": {},
   "source": [
    "## TF 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b27bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 데이터셋 생성\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(100).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ac44e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e9b6d2",
   "metadata": {},
   "source": [
    "## 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4bfb19",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666a6ab8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a57ca",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# 스케줄러 설정\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',    # 모니터링할 지표 (검증 정확도)\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b919d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = EPOCH\n",
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset, \n",
    "    epochs=epoch,\n",
    "    callbacks=[reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr 변경 1e-5 -> 5e-5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95614cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# 메모리 해제\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784407ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7139800",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "evaluation = model.evaluate(val_dataset)\n",
    "print(\"평가 결과:\", evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b65a7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450e39a",
   "metadata": {},
   "source": [
    "## 테스트 문장으로 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b9d3aa",
   "metadata": {},
   "source": [
    "### test.json 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03581d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path =\"/aiffel/aiffel/dktc/data/test.json\"\n",
    "\n",
    "with open(test_data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60da594",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790c32d",
   "metadata": {},
   "source": [
    "### JSON의 key별로 가지는 문장(`value`) 읽으면서 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594863b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_predicst = list()\n",
    "\n",
    "for key in test:\n",
    "    test_sentence = test[key]['text']\n",
    "    \n",
    "    test_encodings = tokenizer(test_sentence, truncation=True, padding=True, max_length=128, return_tensors=\"tf\")\n",
    "    \n",
    "    test_predictions = model.predict({\n",
    "        \"input_ids\": test_encodings[\"input_ids\"],\n",
    "        \"token_type_ids\": test_encodings[\"token_type_ids\"],\n",
    "        \"attention_mask\": test_encodings[\"attention_mask\"]\n",
    "    }) # [ 0.7805823,  2.6188664, -2.0281641, -0.9672525]\n",
    "    test_class_probabilities = tf.nn.softmax(test_predictions.logits, axis=-1).numpy() # [[0.13297564 0.8358507  0.00801584 0.02315779]]\n",
    "    test_predicted_class = np.argmax(test_class_probabilities, axis=1) # [ 1 ]\n",
    "    test_predicst.append(test_predicted_class[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbc9033",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b83751",
   "metadata": {},
   "source": [
    "# submission\n",
    "`submission.csv`파일을 위한 DataFrame 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f82bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelnum_to_text(x):\n",
    "    if x == 1 : # 갈취\n",
    "        return '01'\n",
    "    if x == 2 : # 직장\n",
    "        return '02'\n",
    "    if x == 3 : # 기타\n",
    "        return '03'\n",
    "    if x == 0 : # 협박 \n",
    "        return '00'\n",
    "\n",
    "submission = pd.DataFrame({'class':test_predicst}, index=list(test.keys()))\n",
    "submission['class'] = submission['class'].apply(labelnum_to_text)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa64b0c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1217a8",
   "metadata": {},
   "source": [
    "## 날짜별 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea92b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시간 가져오기\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# 날짜와 시간을 원하는 형식으로 포맷팅\n",
    "date_time_str = now.strftime(\"%Y%m%dT%H%M\")\n",
    "\n",
    "# 파일명 생성\n",
    "file_name = f\"submission{date_time_str}.csv\"\n",
    "\n",
    "# submission.csv 파일을 날짜패턴 합쳐 만들기\n",
    "submission.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86a2df",
   "metadata": {},
   "source": [
    "### `preprocess_sentence2()` 전처리 출발 케이스"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
